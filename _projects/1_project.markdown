---
layout: page
title: Deep Generative Models
description: Deep generative models are fascinating. This project attemps to study and contrast the various approaches for generative modelling.
img: /assets/img/GAN_celeba_30.png
---

Generative Modelling is the method of learning data distributions in an unsupervised manner which could be used to generate new data-points. Leveraging recent advances in deep learning, generative modelling when carried out on images leads to extremely realistic looking synthetic examples. In this project, we study 3 frameworks that are popularly used for this purpose: Generative Adversarial Networks (GANs) , Variational Auto-encoders (VAEs) and Normalizing Flows (NFs).


The codes for Generative Adversarial Networks and its variations can be found [here](https://github.com/saurabhdash/DeepGenerativeModels-GANandWGAN){:target="\_blank"}.
The report can be found [here]({{ site.baseurl }}{{post.url}}/assets/pdf/Stat_ML_Report.pdf){:target="\_blank"}.


## Generative Adversarial Networks ##
### Introduction ###

Generative Adversarial Networks (GANs) \[[1](https://arxiv.org/abs/1406.2661){:target="\_blank"}\] consists of 2 Neural Networks playing a min-max game where the Generator ($$\mathbf{G}$$) attempts to fool the discriminator ($$\mathbf{D}$$) and the discriminator attempts to catch the synthetic generated samples.

GANs provide an elegant solution to model an unsupervised learning problem as a supervised learning problem. The discriminator is a neural network that takes an image and outputs a probability of the image being real. The generator is a neural network that takes a noise vector as an input and converts it into an image.

The discriminator attempts to increase the expected log likelihood of detecting a real example by maximizing $$\mathbb{E}_{x \sim p_r(x)}[\log(D(x))]$$ and increase the expected log likelihood of detecting a fake example by maximizing $$\mathbb{E}_{x \sim p_g(x)}[\log(1 - D(x))]$$.

While the generator tries to minimize the discriminator's probability of detecting a fake sample by minimizing $$\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$$. Ideally as the training progresses one expects both the networks to get better over time.
Thus the GAN optimization can be formulated as:

$$
\begin{alignedat}{2}
    \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \enspace \min\limits_{G} \: \max\limits_{D} L_{GAN}(G,D) = \mathbb{E}_{x \sim p_r(x)}[\log(D(x))] + \mathbb{E}_{x \sim p_g(x)}[\log(1 - D(x))]
\end{alignedat}
$$

Once the training is over, new samples can be generated by sampling from $$p_z(z)$$ and passing it through the generator $$\mathbf{G}$$.

<br/>
<br/>
<div style="text-align: center"><img src="/assets/img/GAN.PNG" width="700" height="auto" /></div>
<div class="col three caption">
    GAN Architecture
</div>
<br/>
<br/>

### Results ###

<div class="img_row">
    <img class="col one left" src="{{ site.baseurl }}/assets/img/WGAN_MNIST_1.png" alt="" title="Epoch 1" />
    <img class="col one left" src="{{ site.baseurl }}/assets/img/WGAN_MNIST_10.png" alt="" title="Epoch 10"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/WGAN_MNIST_20.png" alt="" title="Epoch 20"/>
</div>
<div class="col three caption">
    Evolution of GAN generated MNIST samples as training progresses. Left: Epoch 1, Middle: Epoch 10, Right: Epoch 20
</div>

<div class="img_row">
    <img class="col one left" src="{{ site.baseurl }}/assets/img/GAN_celeba_1.png" alt="" title="Epoch 1"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/GAN_celeba_10.png" alt="" title="Epoch 10"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/GAN_celeba_20.png" alt="" title="Epoch 20"/>
</div>
<div class="col three caption">
    Evolution of GAN generated CelebA samples as training progresses. Left: Epoch 1, Middle: Epoch 10, Right: Epoch 20
</div>

<br />
<br />
<br />

But, what if we interpolated between the noise vectors corresponding to 2 outputs?

<div class="img_row">
    <img class="col three" src="{{ site.baseurl }}/assets/img/interpolation_gan.PNG" alt="" title="noise interpolation"/>
</div>
<div class="col three caption">
    Interpolation in the noise domain
</div>


if the noise vectors corresponding to different outputs are interpolated, there is a smooth transition between the outputs which also captures an intermediate output.

<br />
<br />
<br />

Do the noise dimensions encode human intpretable features?

The noise vector had a size of 10 - in an effort to force the network to use few "descriptors" to generate an image. We sweep each of the latent dimensions in the noise vector keeping the other dimensions fixed. In figures below, each row shows the output when the corresponding is changed keeping the others constant. We can see that some of the noise dimensions encode visual features like background color or number of loops in the digits.

<div class="img_row">
    <img class="col onebytwo" src="{{ site.baseurl }}/assets/img/latent_sweep.png" alt="" title="MNIST sweep"/>
    <img class="col onebytwo" src="{{ site.baseurl }}/assets/img/latent_sweep_celeba.png" alt="" title="CelebA sweep"/>
    <!-- <img class="col one left" src="{{ site.baseurl }}/assets/img/3.jpg" alt="" title="example image" height="500"/> -->
</div>
<div class="col three caption">
    Latent dimension sweep
</div>


### Issues with GAN Training ###
It was observed that GANs are very sensitive to the choice of hyperparamters and the training in general is unstable. This is because we are trying to find a Nash equilibrium in a min-max game which might not always exist. 


Another problem that was frequently encountered was Mode Collapse where the generator was stuck in one of the many modes of the real distribution and always generated the same result. One of ways this was solved was by using one-sided label smoothening where the real samples were assigned a random value between 0.7 and 0.9 instead of 1. This prevented the discriminator from making overconfident predictions and quickly reaching the optimal value; allowing time for the generator to catch up, improving the quality of samples generated.


As discussed above, the vanilla GAN formulation leads to multiple issues exacerbating the difficulty in optimizing and finding an equilibrium. To alleviate these issues, \[[Arjovsky et. al.](https://arxiv.org/pdf/1701.07875.pdf){:target="\_blank"}\] suggested using the Wasserstein Metric as the loss function which leads us to WGAN.



## Wasserstein GAN ##

It has been observed that the support for the real distribution $$\mathbb{P}_r$$ actually lies in lower dimensions. This creates a major problem because it is very likely to find a perfect discriminator, leading to vanishing gradients. If the supports for real distribution $$\mathbb{P}_r$$ and generator distribution $$\mathbb{P}_{g}$$ do not align, the vanilla GAN loss which has been shown to minimize the Jensen-Shannon divergence becomes discontinuous \[[2](https://arxiv.org/pdf/1701.07875.pdf){:target="\_blank"}\]. This is where Wasserstein distance in superior.
Wasserstein distance measures the distance between two probability measures and is a smooth measure. It is defined as:


$$
    \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \;\;\;\;\;\;\;\;\;  
    W(\mathbb{P}_{r}, \mathbb{P}_{g}) = \inf_{\gamma \sim \Pi(\mathbb{P}_{r}, \mathbb{P}_{g})} \mathbb{E}_{(x,y) \sim \gamma}[\|x-y\|]
$$


 $$\Pi(\mathbb{P}_{r}, \mathbb{P}_{g})$$ is the set of all possible joint distributions between $$\mathbb{P}_{r}$$ and $$\mathbb{P}_{g}$$. 


We sample the joint distribution $$\gamma$$ from this set that minimizes the expected distance between all possible points $$x$$ and $$y$$ over which $$\mathbb{P}_{r}$$ and $$\mathbb{P}_{g}$$ are jointly defined. 

In this current from the expression in intractable. \[[2](https://arxiv.org/pdf/1701.07875.pdf){:target="\_blank"}\] used Kantorovich-Rubinstein duality to obtain the equivalent expression:

$$
    \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \;\;\;\;\;\;\;\;\;
    W(\mathbb{P}_{r}, \mathbb{P}_{g}) = \sup_{\|f\|_{L} \leq K} \mathbb{E}_{p_{r}}[f(x)] - \mathbb{E}_{p_{g}}[f(x)]
$$

But the above equation requires that the discriminator function $$f$$ be K-Lipschitz continuous. This adds an extra constraint on the parameters of the discriminator. \[[Arjovsky et. al.](https://arxiv.org/pdf/1701.07875.pdf){:target="\_blank"}\] solved this by simply clamping the values of the parameters to restrict them in a range [-c,c] to enforce the K-Lipschitz constraint. 

Instead of clipping, \[[Gulrajani et. al.](https://arxiv.org/pdf/1704.00028.pdf){:target="\_blank"}\] showed that the optimal discriminator or critic $$f^{*}$$ has gradient 1 almost everywhere under $$\mathbb{P}_{r}$$ and $$\mathbb{P}_{g}$$. This could be added as an extra penalty term in the WGAN loss function leading to WGAN-GP (gradient penalty).

$$
    \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \;\;\;\;\;\;\;\;\;
    \mathcal{L}_{WGAN-GP} = \mathcal{L}_{WGAN} + \lambda(\| \nabla_{\hat{x}} D_{w}(\hat{x}) \|_{2} - 1)^2

$$

### Results ###

Figure below illustrates how WGAN overcomes the limitations faced by GANs in multi-modal datasets. In the first row, DCGAN collapses on a single mode while in the second row, WGAN is able to learn the real distribution by generating data in all the modes. 


<div class="img_row">
    <img class="col one left" src="{{ site.baseurl }}/assets/img/8gaussian_GAN.png" alt="" title="8 gaussian"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/25gaussian_GAN.png" alt="" title="25 gaussian"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/swissroll_GAN.png" alt="" title="swiss roll"/>
</div>
<div class="col three caption">
    Failure to learn multi-modal data by GANs due to mode collapse.
</div>

<div class="img_row">
    <img class="col one left" src="{{ site.baseurl }}/assets/img/8gaussian.png" alt="" title="8 gaussian"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/25gaussian.png" alt="" title="25 gaussian"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/swissroll.png" alt="" title="swiss roll"/>
</div>
<div class="col three caption">
    Better Learning of multi-modal data by WGANs.
</div>

<div class="img_row">
    <img class="col one left" src="{{ site.baseurl }}/assets/img/WGAN_celeba_1.png" alt="" title="Epoch 1"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/WGAN_celeba_10.png" alt="" title="Epoch 10"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/WGAN_celeba_20.png" alt="" title="Epoch 20"/>
</div>
<div class="col three caption">
    Evolution of WGAN-GP generated CelebA samples as training progresses. Left: Epoch 1, Middle: Epoch 10, Right: Epoch 20
</div>

As we can see, the samples are of higher fidelity compared to vanilla GANs, and more diverse in nature.


## References ##
[1] Goodfellow, Ian, et al. “Generative adversarial nets.” NIPS, 2014. 
<br/>
[2] Martin Arjovsky, Soumith Chintala, and Léon Bottou. “Wasserstein GAN.” arXiv preprint arXiv:1701.07875 (2017).

<!-- 
To give your project a background in the portfolio page, just add the img tag to the front matter like so:

    ---
    layout: page
    title: Project
    description: a project with a background image. 
    img: /assets/img/12.jpg
    ---


<div class="img_row">
    <img class="col one left" src="{{ site.baseurl }}/assets/img/1.jpg" alt="" title="example image" height="500"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/2.jpg" alt="" title="example image" height="500"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/3.jpg" alt="" title="example image" height="500"/>
</div>
<div class="col three caption">
    Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles.
</div>
<div class="img_row">
    <img class="col three left" src="{{ site.baseurl }}/assets/img/5.jpg" alt="" title="example image"/>
</div>
<div class="col three caption">
    This image can also have a caption. It's like magic.
</div>

You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, *bled* for your project, and then.... you reveal it's glory in the next row of images.


<div class="img_row">
    <img class="col two left" src="{{ site.baseurl }}/assets/img/6.jpg" alt="" title="example image"/>
    <img class="col one left" src="{{ site.baseurl }}/assets/img/11.jpg" alt="" title="example image"/>
</div>
<div class="col three caption">
    You can also have artistically styled 2/3 + 1/3 images, like these.
</div>


<br/><br/>


The code is simple. Just add a col class to your image, and another class specifying the width: one, two, or three columns wide. Here's the code for the last row of images above:

<div class="img_row">
    <img class="col two left" src="/img/6.jpg"/>
    <img class="col one left" src="/img/11.jpg"/>
</div> -->
