<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Saurabh Dash | Deep Generative Models</title>
  <meta name="description" content="A beautiful Jekyll theme for academics">

  

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/projects/3_project/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <a class="site-title" href="/">
        
        <strong>Saurabh</strong> Dash
    </a>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">About</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">Blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="/projects/">Projects</a>
          
        
          
            <a class="page-link" href="/publications/">Publications</a>
          
        
          
        

        <!-- CV link -->
        <a class="page-link" href="/assets/pdf/Curriculum_Vitae___Saurabh_Dash.pdf">CV</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Deep Generative Models</h1>
    <h5 class="post-description">Deep generative models are fascinating. This project attemps to study and contrast the various approaches for generative modelling.</h5>
  </header>

  <article class="post-content Deep Generative Models clearfix">
    <p>Generative Modelling is the method of learning data distributions in an unsupervised manner which could be used to generate new data-points. Leveraging recent advances in deep learning, generative modelling when carried out on images leads to extremely realistic looking synthetic examples. In this project, we study 3 frameworks that are popularly used for this purpose: Generative Adversarial Networks (GANs) , Variational Auto-encoders (VAEs) and Normalizing Flows (NFs).</p>

<p>The codes for Generative Adversarial Networks and its variations can be found <a href="https://github.com/saurabhdash/DeepGenerativeModels-GANandWGAN" target="\_blank">here</a>.
The report can be found <a href="/assets/pdf/Stat_ML_Report.pdf" target="\_blank">here</a>.</p>

<h2 id="generative-adversarial-networks">Generative Adversarial Networks</h2>
<h3 id="introduction">Introduction</h3>

<p>Generative Adversarial Networks (GANs) [<a href="https://arxiv.org/abs/1406.2661" target="\_blank">1</a>] consists of 2 Neural Networks playing a min-max game where the Generator (<script type="math/tex">\mathbf{G}</script>) attempts to fool the discriminator (<script type="math/tex">\mathbf{D}</script>) and the discriminator attempts to catch the synthetic generated samples.</p>

<p>GANs provide an elegant solution to model an unsupervised learning problem as a supervised learning problem. The discriminator is a neural network that takes an image and outputs a probability of the image being real. The generator is a neural network that takes a noise vector as an input and converts it into an image.</p>

<p>The discriminator attempts to increase the expected log likelihood of detecting a real example by maximizing <script type="math/tex">\mathbb{E}_{x \sim p_r(x)}[\log(D(x))]</script> and increase the expected log likelihood of detecting a fake example by maximizing <script type="math/tex">\mathbb{E}_{x \sim p_g(x)}[\log(1 - D(x))]</script>.</p>

<p>While the generator tries to minimize the discriminator’s probability of detecting a fake sample by minimizing <script type="math/tex">\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]</script>. Ideally as the training progresses one expects both the networks to get better over time.
Thus the GAN optimization can be formulated as:</p>

<script type="math/tex; mode=display">\begin{alignedat}{2}
\min\limits_{G} \: \max\limits_{D} L_{GAN}(G,D) = \mathbb{E}_{x \sim p_r(x)}[\log(D(x))] + \mathbb{E}_{x \sim p_g(x)}[\log(1 - D(x))]
\end{alignedat}</script>

<p>Once the training is over, new samples can be generated by sampling from <script type="math/tex">p_z(z)</script> and passing it through the generator <script type="math/tex">\mathbf{G}</script>.</p>

<p><br />
<br /></p>
<div style="text-align: center"><img src="/assets/img/GAN.PNG" width="700" height="auto" /></div>
<div class="col three caption">
    GAN Architecture
</div>
<p><br />
<br /></p>

<h3 id="results">Results</h3>

<div class="img_row">
    <img class="col one left" src="/assets/img/WGAN_MNIST_1.png" alt="" title="Epoch 1" />
    <img class="col one left" src="/assets/img/WGAN_MNIST_10.png" alt="" title="Epoch 10" />
    <img class="col one left" src="/assets/img/WGAN_MNIST_20.png" alt="" title="Epoch 20" />
</div>
<div class="col three caption">
    Evolution of GAN generated MNIST samples as training progresses. Left: Epoch 1, Middle: Epoch 10, Right: Epoch 20
</div>

<div class="img_row">
    <img class="col one left" src="/assets/img/GAN_celeba_1.png" alt="" title="Epoch 1" />
    <img class="col one left" src="/assets/img/GAN_celeba_10.png" alt="" title="Epoch 10" />
    <img class="col one left" src="/assets/img/GAN_celeba_20.png" alt="" title="Epoch 20" />
</div>
<div class="col three caption">
    Evolution of GAN generated CelebA samples as training progresses. Left: Epoch 1, Middle: Epoch 10, Right: Epoch 20
</div>

<p><br />
<br />
<br /></p>

<h4 id="but-what-if-we-interpolated-between-the-noise-vectors-corresponding-to-2-outputs">But, what if we interpolated between the noise vectors corresponding to 2 outputs?</h4>

<p>if the noise vectors corresponding to different outputs are interpolated, there is a smooth transition between the outputs which also captures an intermediate output.</p>

<p><br /></p>

<div class="img_row">
    <img class="col three" src="/assets/img/interpolation_gan.PNG" alt="" title="noise interpolation" />
</div>
<div class="col three caption">
    Interpolation in the noise domain
</div>

<p><br />
<br /></p>

<h4 id="do-the-noise-dimensions-encode-human-interpretable-features">Do the noise dimensions encode human interpretable features?</h4>

<p>The noise vector had a size of 10 - in an effort to force the network to use few “descriptors” to generate an image. We sweep each of the latent dimensions in the noise vector keeping the other dimensions fixed. In figures below, each row shows the output when the corresponding is changed keeping the others constant. We can see that some of the noise dimensions encode visual features like background color or number of loops in the digits.</p>

<div class="img_row">
    <img class="col onebytwo" src="/assets/img/latent_sweep.png" alt="" title="MNIST sweep" />
    <img class="col onebytwo" src="/assets/img/latent_sweep_celeba.png" alt="" title="CelebA sweep" />
    <!-- <img class="col one left" src="/assets/img/3.jpg" alt="" title="example image" height="500"/> -->
</div>
<div class="col three caption">
    Latent dimension sweep
</div>

<h3 id="issues-with-gan-training">Issues with GAN Training</h3>
<p>It was observed that GANs are very sensitive to the choice of hyperparamters and the training in general is unstable. This is because we are trying to find a Nash equilibrium in a min-max game which might not always exist.</p>

<p>Another problem that was frequently encountered was Mode Collapse where the generator was stuck in one of the many modes of the real distribution and always generated the same result. One of ways this was solved was by using one-sided label smoothening where the real samples were assigned a random value between 0.7 and 0.9 instead of 1. This prevented the discriminator from making overconfident predictions and quickly reaching the optimal value; allowing time for the generator to catch up, improving the quality of samples generated.</p>

<p>As discussed above, the vanilla GAN formulation leads to multiple issues exacerbating the difficulty in optimizing and finding an equilibrium. To alleviate these issues, [<a href="https://arxiv.org/pdf/1701.07875.pdf" target="\_blank">Arjovsky et. al.</a>] suggested using the Wasserstein Metric as the loss function which leads us to WGAN.</p>

<h2 id="wasserstein-gan">Wasserstein GAN</h2>

<p>It has been observed that the support for the real distribution <script type="math/tex">\mathbb{P}_r</script> actually lies in lower dimensions. This creates a major problem because it is very likely to find a perfect discriminator, leading to vanishing gradients. If the supports for real distribution <script type="math/tex">\mathbb{P}_r</script> and generator distribution <script type="math/tex">\mathbb{P}_{g}</script> do not align, the vanilla GAN loss which has been shown to minimize the Jensen-Shannon divergence becomes discontinuous [<a href="https://arxiv.org/pdf/1701.07875.pdf" target="\_blank">2</a>]. This is where Wasserstein distance in superior.
Wasserstein distance measures the distance between two probability measures and is a smooth measure. It is defined as:</p>

<script type="math/tex; mode=display">W(\mathbb{P}_{r}, \mathbb{P}_{g}) = \inf_{\gamma \sim \Pi(\mathbb{P}_{r}, \mathbb{P}_{g})} \mathbb{E}_{(x,y) \sim \gamma}[\|x-y\|]</script>

<p><script type="math/tex">\Pi(\mathbb{P}_{r}, \mathbb{P}_{g})</script> is the set of all possible joint distributions between <script type="math/tex">\mathbb{P}_{r}</script> and <script type="math/tex">\mathbb{P}_{g}</script>.</p>

<p>We sample the joint distribution <script type="math/tex">\gamma</script> from this set that minimizes the expected distance between all possible points <script type="math/tex">x</script> and <script type="math/tex">y</script> over which <script type="math/tex">\mathbb{P}_{r}</script> and <script type="math/tex">\mathbb{P}_{g}</script> are jointly defined.</p>

<p>In this current from the expression in intractable. [<a href="https://arxiv.org/pdf/1701.07875.pdf" target="\_blank">2</a>] used Kantorovich-Rubinstein duality to obtain the equivalent expression:</p>

<script type="math/tex; mode=display">W(\mathbb{P}_{r}, \mathbb{P}_{g}) = \sup_{\|f\|_{L} \leq K} \mathbb{E}_{p_{r}}[f(x)] - \mathbb{E}_{p_{g}}[f(x)]</script>

<p>But the above equation requires that the discriminator function <script type="math/tex">f</script> be K-Lipschitz continuous. This adds an extra constraint on the parameters of the discriminator. [<a href="https://arxiv.org/pdf/1701.07875.pdf" target="\_blank">Arjovsky et. al.</a>] solved this by simply clamping the values of the parameters to restrict them in a range [-c,c] to enforce the K-Lipschitz constraint.</p>

<p>Instead of clipping, [<a href="https://arxiv.org/pdf/1704.00028.pdf" target="\_blank">Gulrajani et. al.</a>] showed that the optimal discriminator or critic <script type="math/tex">f^{*}</script> has gradient 1 almost everywhere under <script type="math/tex">\mathbb{P}_{r}</script> and <script type="math/tex">\mathbb{P}_{g}</script>. This could be added as an extra penalty term in the WGAN loss function leading to WGAN-GP (gradient penalty).</p>

<script type="math/tex; mode=display">\mathcal{L}_{WGAN-GP} = \mathcal{L}_{WGAN} + \lambda(\| \nabla_{\hat{x}} D_{w}(\hat{x}) \|_{2} - 1)^2</script>

<h3 id="results-1">Results</h3>

<p>Figure below illustrates how WGAN overcomes the limitations faced by GANs in multi-modal datasets. In the first row, DCGAN collapses on a single mode while in the second row, WGAN is able to learn the real distribution by generating data in all the modes.</p>

<div class="img_row">
    <img class="col one left" src="/assets/img/8gaussian_GAN.png" alt="" title="8 gaussian" />
    <img class="col one left" src="/assets/img/25gaussian_GAN.png" alt="" title="25 gaussian" />
    <img class="col one left" src="/assets/img/swissroll_GAN.png" alt="" title="swiss roll" />
</div>
<div class="col three caption">
    Failure to learn multi-modal data by GANs due to mode collapse.
</div>

<div class="img_row">
    <img class="col one left" src="/assets/img/8gaussian.png" alt="" title="8 gaussian" />
    <img class="col one left" src="/assets/img/25gaussian.png" alt="" title="25 gaussian" />
    <img class="col one left" src="/assets/img/swissroll.png" alt="" title="swiss roll" />
</div>
<div class="col three caption">
    Better Learning of multi-modal data by WGANs.
</div>

<div class="img_row">
    <img class="col one left" src="/assets/img/WGAN_celeba_1.png" alt="" title="Epoch 1" />
    <img class="col one left" src="/assets/img/WGAN_celeba_10.png" alt="" title="Epoch 10" />
    <img class="col one left" src="/assets/img/WGAN_celeba_20.png" alt="" title="Epoch 20" />
</div>
<div class="col three caption">
    Evolution of WGAN-GP generated CelebA samples as training progresses. Left: Epoch 1, Middle: Epoch 10, Right: Epoch 20
</div>

<p>As we can see, the samples are of higher fidelity compared to vanilla GANs, and more diverse in nature.</p>

<h2 id="references">References</h2>
<p>[1] Goodfellow, Ian, et al. “Generative adversarial nets.” NIPS, 2014. 
<br />
[2] Martin Arjovsky, Soumith Chintala, and Léon Bottou. “Wasserstein GAN.” arXiv preprint arXiv:1701.07875 (2017).</p>

<!-- 
To give your project a background in the portfolio page, just add the img tag to the front matter like so:

    ---
    layout: page
    title: Project
    description: a project with a background image. 
    img: /assets/img/12.jpg
    ---


<div class="img_row">
    <img class="col one left" src="/assets/img/1.jpg" alt="" title="example image" height="500"/>
    <img class="col one left" src="/assets/img/2.jpg" alt="" title="example image" height="500"/>
    <img class="col one left" src="/assets/img/3.jpg" alt="" title="example image" height="500"/>
</div>
<div class="col three caption">
    Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles.
</div>
<div class="img_row">
    <img class="col three left" src="/assets/img/5.jpg" alt="" title="example image"/>
</div>
<div class="col three caption">
    This image can also have a caption. It's like magic.
</div>

You can also put regular text between your rows of images. Say you wanted to write a little bit about your project before you posted the rest of the images. You describe how you toiled, sweated, *bled* for your project, and then.... you reveal it's glory in the next row of images.


<div class="img_row">
    <img class="col two left" src="/assets/img/6.jpg" alt="" title="example image"/>
    <img class="col one left" src="/assets/img/11.jpg" alt="" title="example image"/>
</div>
<div class="col three caption">
    You can also have artistically styled 2/3 + 1/3 images, like these.
</div>


<br/><br/>


The code is simple. Just add a col class to your image, and another class specifying the width: one, two, or three columns wide. Here's the code for the last row of images above:

<div class="img_row">
    <img class="col two left" src="/img/6.jpg"/>
    <img class="col one left" src="/img/11.jpg"/>
</div> -->

  </article>

  

  

</div>

      </div>
    </div>

    <!-- To add footer, uncomment this and make changes in the _config file for the content.
<footer>
Read more: https://html.com/tags/comment-tag/#ixzz6AO49fXqK
  <div class="wrapper">
    &copy; Copyright 2020 Saurabh Dash.
    
    
  </div>

</footer>
-->

    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">


<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-155736466-1', 'auto');
ga('send', 'pageview');
</script>



  </body>

</html>
